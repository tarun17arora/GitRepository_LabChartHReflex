{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Function_readLabChartMat import get_pages_data, backRMS, autoEventDetection, manualEventDetect, avgVals, get_page_info, importPagesLabMat,mark_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"R:\\Prosjekter\\ELECTROPHYSIOLOGY_PD_1000214\\HealthyControl\\EHC03\\EHC03_ShortTrial_15trials_30042024.mat\"\n",
    "preTrigger = 50 #time in msec\n",
    "postTrigger = 100 #time in msec\n",
    "samp_rate = 4000\n",
    "pre_time_ms = 50 \n",
    "post_time_ms = 100\n",
    "avgFact = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_by_block, com) = importPagesLabMat(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(data_by_block[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "print(len(com))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_pages = mark_pages(filename,samp_rate, pre_time_ms, post_time_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNamePath = filename\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# using scipy to load matlab file. Note data is imported as arrays ndarray\n",
    "mat = scipy.io.loadmat(fileNamePath)\n",
    "\n",
    "# extracting data\n",
    "allData = mat['data']\n",
    "allData = allData.astype(np.double)\n",
    "com = mat['com']\n",
    "\n",
    "# extracting dataStart and dataEnd indices + defining the number of blocks\n",
    "dataStart = mat['datastart']\n",
    "dataStart = dataStart.astype(np.int32)\n",
    "dataEnd = mat['dataend']\n",
    "dataEnd = dataEnd.astype(np.int32)\n",
    "nosBlocks = dataStart.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_by_block, com) = importPagesLabMat(filename)\n",
    "nos_blocks = len(data_by_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_by_block = get_page_info(com, samp_rate, pre_time_ms, post_time_ms)\n",
    "\n",
    "# creating marked_pages as a copy of data_by_block for further modifications\n",
    "marked_pages = data_by_block.copy()\n",
    "unique_blocks = np.unique(com[:, 1])\n",
    "block_no = 0\n",
    "pg_no = 0  # this is page within a block\n",
    "given_page_no = 1  # this is labChart page number - note this so that page number doesn't go back to 1 for each new block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Getting data sorted by blocks \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m marked_pages \u001b[38;5;241m=\u001b[39m \u001b[43mmark_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43msamp_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_time_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_time_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m club_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack(marked_pages)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Identify page numbers and remove zeros\u001b[39;00m\n",
      "File \u001b[1;32mr:\\Prosjekter\\ELECTROPHYSIOLOGY_PD_1000214\\GitEPhysPD\\GitRepository_LabChartHReflex\\Function_readLabChartMat.py:118\u001b[0m, in \u001b[0;36mmark_pages\u001b[1;34m(filename, samp_rate, pre_time_ms, post_time_ms)\u001b[0m\n\u001b[0;32m    116\u001b[0m # determining the \"number of the pages\" and \"data point in each page\" within the current block\n\u001b[0;32m    117\u001b[0m pages_in_block = pages_info_for_block.shape[0] #determining the number of pages within this block\n\u001b[1;32m--> 118\u001b[0m #block_data_length = len(data_for_block[block_no])  # determing the number of datapoints in each channel for this block # recent change 22-10-2024\n\u001b[0;32m    119\u001b[0m \n\u001b[0;32m    120\u001b[0m # creating a zero matrix of size of block length\n\u001b[0;32m    121\u001b[0m pagelabel_shape = np.shape(data_for_block[0]) #note: specifying the shape of the ndarray to be created \n\u001b[0;32m    122\u001b[0m page_label = np.zeros(pagelabel_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Getting data sorted by blocks \n",
    "marked_pages = mark_pages(filename,samp_rate, pre_time_ms, post_time_ms)\n",
    "\n",
    "club_data = np.hstack(marked_pages)\n",
    "    \n",
    "# Identify page numbers and remove zeros\n",
    "page_nos = np.unique(club_data[-1])\n",
    "page_nos = page_nos[page_nos > 0] # note: selecting data that belongs to pages\n",
    "\n",
    "#starting a loop to create pages with all channels information in that page\n",
    "pages = []\n",
    "for pg_no in page_nos:\n",
    "    ind_pg = np.where(club_data[-1] == pg_no)[0] #finding the indices of data belonging to current page \n",
    "    pg_val = club_data[:,ind_pg] #double check if there is a need to switch columns and rows\n",
    "    pages.append(pg_val) #maybe first convert to list before appending?\n",
    "\n",
    "# OPTIONAL: averaging the pages if asked by the user\n",
    "if avgFact != 0:\n",
    "    a1 = 0\n",
    "    diff = avgFact\n",
    "    noLots = int(len(pages) / avgFact) # this gives number of resulting pages after averaging\n",
    "    chNos = len(pages[0]) # this gives number of channels in the first page - should be common to all pages\n",
    "    new_lotArray = []\n",
    "    for lotNo in range(1,noLots+1): #double check +1 correction\n",
    "        st_ind = a1 + (lotNo - 1)*diff #using arithmetic mean\n",
    "        end_ind = st_ind + diff \n",
    "        useData = pages[st_ind:end_ind]\n",
    "        mean_ChArray = []\n",
    "        for chNo in range(0, chNos):\n",
    "            pg_array4mean = []\n",
    "            for pgNo in range(0, len(useData)):\n",
    "                ind_Chnl = useData[pgNo][chNo]\n",
    "                pg_array4mean.append(ind_Chnl)\n",
    "            mean_pgArray = np.mean(pg_array4mean,axis = 0)\n",
    "            mean_ChArray.append(mean_pgArray)\n",
    "        new_lotArray.append(mean_ChArray)\n",
    "    pages = new_lotArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
