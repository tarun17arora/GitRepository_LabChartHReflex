{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19621afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53413f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Function_readLabChartMat import get_pages_data, backRMS, autoEventDetection, manualEventDetect, avgVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773fa994",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ptID = \"default_value\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75b9f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating inputs and creating the path\n",
    "import os\n",
    "cmnPath = r'R:\\Prosjekter\\ELECTROPHYSIOLOGY_PD_1000214'\n",
    "\n",
    "\n",
    "if ptID.startswith('EHC'):\n",
    "    grp = 'HealthyControl'\n",
    "elif ptID.startswith('EPD'):\n",
    "    grp ='ParkinsonsDisease'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93511f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating path based on the inputs and changing the working director\n",
    "filePath = os.path.join(cmnPath,grp,ptID)\n",
    "os.chdir(filePath)\n",
    "\n",
    "# locating the excel file \n",
    "xlFile = [f for f in os.listdir() if f.endswith('.xlsx') and f.startswith(ptID)]\n",
    "print(xlFile)\n",
    "\n",
    "xlPath = os.path.join(filePath,xlFile[0])\n",
    "print(xlPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35c3670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data from excel file\n",
    "#READING EXCEL FILE\n",
    "    \n",
    "xlData = pd.ExcelFile(xlPath)     \n",
    "xlDF = pd.read_excel(xlData,sheet_name=\"H-reflex\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5be427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how  you can access to specific sheet of excel \n",
    "    # so, reading the entire excel sheet first and storing its information will be more efficient\n",
    "# Display the indices (as a list of (row, column) tuples)\n",
    "\n",
    "fileName_HMCurve = xlDF.iloc[13,1]\n",
    "fileName_HMCurve = fileName_HMCurve + \".mat\"\n",
    "print(fileName_HMCurve)\n",
    "fileName_shortTrials = xlDF.iloc[19,1]\n",
    "fileName_shortTrials = fileName_shortTrials + \".mat\"\n",
    "print(fileName_shortTrials)\n",
    "fileName_longTrials = xlDF.iloc[24,1]\n",
    "fileName_longTrials = fileName_longTrials + \".mat\"\n",
    "print(fileName_longTrials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46dbea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(filePath,fileName_shortTrials)\n",
    "preTrigger = 50 #time in msec\n",
    "postTrigger = 100 #time in msec\n",
    "samp_rate = 4000\n",
    "pre_time_ms = 50 \n",
    "post_time_ms = 100\n",
    "avgFact = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling function to obtain the pages\n",
    "pages = get_pages_data(filename, samp_rate, pre_time_ms, post_time_ms, avgFact)\n",
    "len(pages[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "chNo = 1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "timeAxis = np.linspace(-pre_time_ms,post_time_ms,len(pages[0][0]))\n",
    "\n",
    "hOnset_ms = 35\n",
    "mOnset_ms = 5\n",
    "hrangeTime_ms = 30\n",
    "mrangeTime_ms = 20\n",
    "\n",
    "for pg in range(len(pages)): \n",
    "    plt.plot(timeAxis,(pages[pg][chNo-1]*1000))\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(x=[hOnset_ms, mOnset_ms], ymin=ymin, ymax=ymax, colors='green', linestyles='dashed', label='vlines')\n",
    "plt.vlines(x=[hOnset_ms+hrangeTime_ms, mOnset_ms+mrangeTime_ms], ymin=ymin, ymax=ymax, colors='r', linestyles='dashed', label='vlines')\n",
    "plt.ylabel(\"Amplitude (mV)\")\n",
    "plt.xlabel(\"Time(ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05b2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAmplitudes_mV = []\n",
    "MAmplitudes_mV = []\n",
    "for pgNo in range(len(pages)):\n",
    "    indEpoch = pages[pgNo][chNo-1]\n",
    "    hmSignal = manualEventDetect(indEpoch, pre_time_ms, samp_rate, hOnset_ms, mOnset_ms, hrangeTime_ms,mrangeTime_ms)\n",
    "    hAmp = round((max(hmSignal[0]) - min(hmSignal[0]))*1000,3)\n",
    "    HAmplitudes_mV.append(hAmp)\n",
    "    mAmp = round((max(hmSignal[1]) - min(hmSignal[1]))*1000,3)\n",
    "    MAmplitudes_mV.append(mAmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5d91cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting backRMS values and preparing it by average of certain values\n",
    "RMS_Signal_StartTime_ms = 50\n",
    "RMS_Signal_EndTime_ms = 1\n",
    "RMS_samp_rate = samp_rate\n",
    "RMS_pre_time_ms = pre_time_ms\n",
    "\n",
    "RMS_signalArray = []\n",
    "Pages_backrms = get_pages_data(filename, samp_rate, pre_time_ms, post_time_ms, avgFact = 1)\n",
    "BackgroundRMS_mv = []\n",
    "for pgNo_rms in range(len(Pages_backrms)):\n",
    "    indEpoch_rms = Pages_backrms[pgNo_rms][chNo-1]\n",
    "    RMS_signal = backRMS(indEpoch_rms, RMS_Signal_StartTime_ms, RMS_Signal_EndTime_ms, RMS_samp_rate, RMS_pre_time_ms)\n",
    "    # removing DC offset\n",
    "    RMS_noDCOffset = RMS_signal - np.mean(RMS_signal)\n",
    "    RMS_signalArray.append(RMS_noDCOffset)\n",
    "    rmsVal = round(np.sqrt(np.mean(RMS_noDCOffset**2))*1000,3)\n",
    "    BackgroundRMS_mv.append(rmsVal)\n",
    "\n",
    "# averaging by avgFact\n",
    "avgBackgroundRMS_mV = avgVals(BackgroundRMS_mv, avgFact)\n",
    "avgBackgroundRMS_mV = [round(num,3) for num in avgBackgroundRMS_mV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909561b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the background RMS\n",
    "RMS_timeax = np.linspace(-RMS_Signal_StartTime_ms, -RMS_Signal_EndTime_ms, len(RMS_signalArray[0]))\n",
    "\n",
    "for RMS_no in range(len(RMS_signalArray)):\n",
    "    plt.plot(RMS_timeax, RMS_signalArray[RMS_no]*1000)\n",
    "plt.ylabel(\"Amplitude (mV)\")\n",
    "plt.xlabel(\"Time(ms)\")\n",
    "xmin, xmax = plt.xlim()\n",
    "\n",
    "plt.hlines(y=np.average(avgBackgroundRMS_mV), xmin=xmin, xmax=xmax, color='red', linestyle='--', label='y = 0.5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "accd6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a df to be exported as excel file\n",
    "partiID =  [ptID] * len(HAmplitudes_mV)\n",
    "group = [grp] * len(HAmplitudes_mV)\n",
    "trialOrder = list(range(1,len(HAmplitudes_mV)+1))\n",
    "dict_outcome = {\"ParticipantID\": partiID, \"Group\": grp, \"TrialOrder\": trialOrder,\"HAmplitudes_mV\": HAmplitudes_mV, \"MAmplitudes_mV\": MAmplitudes_mV, \"avgBackgroundRMS_mV\":avgBackgroundRMS_mV}\n",
    "df_output = pd.DataFrame(dict_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab3daed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading conditions from XL\n",
    "df_frmXL = pd.read_excel(xlData,sheet_name=\"Standing (ShortTrials)\", usecols=\"A:B\", skiprows=8, nrows=15)\n",
    "df_frmXL.rename(columns={df_frmXL.columns[0]: 'TrialOrder', df_frmXL.columns[1]: 'Condition'}, inplace=True)\n",
    "EOpen = df_frmXL['Condition'].str.contains('Open', case=False, na=False)\n",
    "SurfaceFirm = df_frmXL['Condition'].str.contains('Firm', case=False, na=False)\n",
    "DualTask = df_frmXL['Condition'].str.contains('DT', case=False, na=False)\n",
    "\n",
    "#creating complexity\n",
    "complexity_mapping = {\n",
    "    'Eyes Open Firm': 1,\n",
    "    'Eyes Open Foam': 3,\n",
    "    'Eyes Closed Firm': 2,\n",
    "    'Eyes Closed Foam': 4,\n",
    "    'Eyes Closed Foam DT': 5\n",
    "}\n",
    "\n",
    "# Create the 'complexity' column by mapping the values in the existing column\n",
    "Complexity = df_frmXL['Condition'].map(complexity_mapping) \n",
    "\n",
    "dict_forXL = {\"ParticipantID\": partiID, \"EOpen\": EOpen.astype(int), \"SFirm\":SurfaceFirm.astype(int), \n",
    "              \"DTask\": DualTask.astype(int), \"Complexity\": Complexity.astype(int)}\n",
    "df_XLCombined = df_frmXL.assign(**dict_forXL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59898087",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_XLCombined,df_output, on=['ParticipantID', 'TrialOrder'])\n",
    "merged_df = merged_df.sort_values(by='TrialOrder', ascending=True)\n",
    "merged_df['Timestamp'] = pd.Timestamp('now').floor('s')\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b30b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "saveXLSwitch = 1\n",
    "if saveXLSwitch == 1:\n",
    "    XLoutput_file = r'R:\\Prosjekter\\ELECTROPHYSIOLOGY_PD_1000214\\newDatafromPython.xlsx'\n",
    "    #merged_df.to_excel(XLoutput_file, index=False, sheet_name='Merged Data')\n",
    "    xlLoaded = load_workbook(XLoutput_file)\n",
    "\n",
    "    with pd.ExcelWriter(XLoutput_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "        writer.xlLoaded = xlLoaded\n",
    "        # The name of the sheet you want to append to\n",
    "        sheet_name = 'Merged Data'\n",
    "        \n",
    "        # Get the max row in the existing sheet\n",
    "        startrow = writer.sheets[sheet_name].max_row\n",
    "        # Append the DataFrame to the sheet\n",
    "        merged_df.to_excel(writer, sheet_name=sheet_name, startrow=startrow, index=False, header=True)\n",
    "\n",
    "    print(\"Data added to the file\",XLoutput_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e6d2f",
   "metadata": {},
   "source": [
    "# run this pipeline in a separate notebook for multiple inputs for the participant ID\n",
    "import papermill as pm\n",
    "# List of patient IDs\n",
    "# patient_ids = [\"EHC01\", \"EHC02\", \"EHC04\", \"EHC05\", \"EHC06\"]  # add as many as needed\n",
    "patient_ids = [\"EPD01\", \"EPD02\", \"EPD03\", \"EPD04\", \"EPD06\", \"EPD07\", \"EPD08\", \"EPD09\", \"EPD10\", \"EPD11\"]\n",
    "\n",
    "\n",
    "# Execute the notebook for each patient ID\n",
    "for pt_id in patient_ids:\n",
    "    pm.execute_notebook(\n",
    "        'Pipeline_HMAnalysis.ipynb',               # Path to your input notebook\n",
    "        f'output_notebook_{pt_id}.ipynb',       # Save each output with the patient ID\n",
    "        parameters={'ptID': pt_id}              # Pass ptID as a parameter\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
